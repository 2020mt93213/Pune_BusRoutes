{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import required libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMapWithTime\n",
    "from folium.features import DivIcon\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import randomcolor\n",
    "from geopy.distance import distance\n",
    "from datetime import date\n",
    "import time\n",
    "import requests\n",
    "import math\n",
    "from folium.plugins import BeautifyIcon\n",
    "import configparser\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following packages are mainly required to save the folium maps to images (.png)\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "\n",
    "binary = 'C:\\\\Program Files\\\\Mozilla Firefox\\\\firefox.exe'\n",
    "options = Options()\n",
    "options.headless=True\n",
    "options.binary = binary\n",
    "cap = DesiredCapabilities().FIREFOX\n",
    "cap[\"marionette\"] = True\n",
    "driver = webdriver.Firefox(options=options, capabilities=cap, executable_path=\"C:\\geckodriver-v0.26.0-win64\\geckodriver.exe\")\n",
    "\n",
    "import io\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directories\n",
    "resource_directory = \"00_Ntbk_Resources\\\\01_DataAnalysis\\\\00_ProcessedData\\\\PMPML_BusRoutes_July2019\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get the dataset\n",
    "source: http://opendata.punecorporation.org/Citizen/CitizenDatasets/Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we've already cleaned and pre-processed the dataset downloaded from the website, and saved to CSV ile for further use. (refer 00_Ntbk_PuneBusRoutes_DataCollection,Processing,Cleaning.ipynb)\n",
    "# let's just import processed CSVs into our dataframes\n",
    "df_BusRouteShapes = pd.read_csv(f\"{resource_directory}shapes.txt\")\n",
    "df_BusStopTimes = pd.read_csv(f\"{resource_directory}stop_times.txt\", parse_dates= [\"arrival_time\", \"departure_time\"])\n",
    "df_BusStops = pd.read_csv(f\"{resource_directory}stops.txt\")\n",
    "df_BusTrips = pd.read_csv(f\"{resource_directory}trips.txt\")\n",
    "df_TripCalendar = pd.read_csv(f\"{resource_directory}calendar.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Preparation\n",
    "create a dataframe that will contain information of all trips and their stop times at a single point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_BusScheduleInfo = df_BusStopTimes.copy()\n",
    "df_BusScheduleInfo = df_BusScheduleInfo.join(df_BusStops.set_index(\"stop_id\"), on=\"stop_id\")\n",
    "df_BusScheduleInfo = df_BusScheduleInfo.join(df_BusTrips[[\"trip_id\", \"service_id\", \"route_id\", \"trip_headsign\", \"trip_distance\"]].set_index(\"trip_id\"), on=\"trip_id\")\n",
    "df_BusScheduleInfo[\"trip_bgn_time\"] = df_BusScheduleInfo.groupby(\"trip_id\")[\"arrival_time\"].transform(\"first\")\n",
    "df_BusScheduleInfo[\"trip_end_time\"] = df_BusScheduleInfo.groupby(\"trip_id\")[\"arrival_time\"].transform(\"last\")\n",
    "df_BusScheduleInfo[\"trip_duration\"] = df_BusScheduleInfo[\"trip_end_time\"] - df_BusScheduleInfo[\"trip_bgn_time\"]\n",
    "df_BusScheduleInfo[\"trip_bgn_stop_id\"] = df_BusScheduleInfo.groupby(\"trip_id\")[\"stop_id\"].transform(\"first\")\n",
    "df_BusScheduleInfo[\"trip_end_stop_id\"] = df_BusScheduleInfo.groupby(\"trip_id\")[\"stop_id\"].transform(\"last\")\n",
    "\n",
    "df_BusScheduleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# give each trip_id a unique color to represent on the map\n",
    "rand_color = randomcolor.RandomColor()\n",
    "list_TripColor = rand_color.generate(count=len(df_BusScheduleInfo[\"trip_end_stop_id\"].unique()))\n",
    "df_TripColors = pd.DataFrame([list(df_BusScheduleInfo[\"trip_end_stop_id\"].unique()), list_TripColor])\n",
    "df_TripColors = df_TripColors.transpose()\n",
    "df_TripColors.columns = [\"trip_end_stop_id\", \"trip_color\"]\n",
    "df_BusScheduleInfo = df_BusScheduleInfo.join(df_TripColors.set_index(\"trip_end_stop_id\"), on = \"trip_end_stop_id\")\n",
    "\n",
    "df_BusScheduleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BusScheduleInfo[\"trip_id\"].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rearrange the dataframe columns\n",
    "list_ColumnsRearranged = [\"trip_id\", \"service_id\", \"trip_headsign\", \"route_id\", \"trip_distance\", \"trip_color\", \"trip_duration\",\"trip_bgn_time\", \"trip_end_time\", \"trip_bgn_stop_id\", \"trip_end_stop_id\", \"stop_sequence\", \"stop_id\", \"stop_name\", \"stop_lat\", \"stop_lon\", \"arrival_time\", \"departure_time\"]\n",
    "df_BusScheduleInfo = df_BusScheduleInfo[list_ColumnsRearranged]\n",
    "\n",
    "df_BusScheduleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BusScheduleInfo[[\"trip_id\", \"trip_headsign\", \"trip_bgn_time\", \"trip_end_time\", \"trip_duration\"]].sort_values(\"trip_duration\").head(8305)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quickfacts of our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# longest trip (based on trip distance)\n",
    "df_BusScheduleInfo[df_BusScheduleInfo[\"trip_distance\"] == df_BusScheduleInfo[\"trip_distance\"].max()][[\"trip_headsign\",\"trip_distance\"]].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortest trip (based on trip distance)\n",
    "df_BusScheduleInfo[df_BusScheduleInfo[\"trip_distance\"] == df_BusScheduleInfo[\"trip_distance\"].min()][[\"trip_headsign\",\"trip_distance\",\"trip_duration\"]].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# longest trip (based on trip duration)\n",
    "df_BusScheduleInfo[df_BusScheduleInfo[\"trip_duration\"] == df_BusScheduleInfo[\"trip_duration\"].max()][[\"trip_headsign\",\"trip_duration\"]].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortest trip (based on trip duration)\n",
    "df_BusScheduleInfo[df_BusScheduleInfo[\"trip_duration\"] == df_BusScheduleInfo[\"trip_duration\"].min()][[\"trip_headsign\",\"trip_duration\"]].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Get Foursquare location information\n",
    "We must identify unique stop_ids and their co-ordinates to make request for Foursquare API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique stop_ids of destinations for all trips\n",
    "df_trip_destinations = df_BusScheduleInfo[[\"trip_id\", \"trip_end_stop_id\"]]\n",
    "df_trip_destinations = df_trip_destinations.drop_duplicates()\n",
    "df_trip_destinations = df_trip_destinations.sort_values(by=\"trip_end_stop_id\")\n",
    "df_trip_destinations[\"trip_count\"] = df_trip_destinations.groupby(\"trip_end_stop_id\")[\"trip_id\"].transform(\"count\")\n",
    "df_trip_destinations = df_trip_destinations.sort_values(by=\"trip_count\", ascending = False)\n",
    "df_trip_destinations.reset_index(inplace=True, drop=True)\n",
    "df_trip_destinations = df_trip_destinations[[\"trip_end_stop_id\", \"trip_count\"]]\n",
    "df_trip_destinations = df_trip_destinations.drop_duplicates()\n",
    "df_trip_destinations.reset_index(inplace=True, drop=True)\n",
    "df_trip_destinations = df_trip_destinations.join(df_BusStops.set_index(\"stop_id\"), on =\"trip_end_stop_id\")\n",
    "\n",
    "df_trip_destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read credentials required for Foursquare request\n",
    "FoursquareCreds = configparser.ConfigParser()\n",
    "FoursquareCreds.read(\"00_Ntbk_Resources\\\\01_DataAnalysis\\\\FoursquareCredentials.ini\")\n",
    "CLIENT_ID = FoursquareCreds.get('CREDENTIALS','CLIENT_ID') # Foursquare ID\n",
    "CLIENT_SECRET = FoursquareCreds.get('CREDENTIALS','CLIENT_SECRET') # Foursquare Secret\n",
    "\n",
    "# define attributes required for Foursquare request\n",
    "VERSION = date.today().strftime(\"%Y%m%d\") # Foursquare API version\n",
    "RADIUS = 1000 # define radius "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form url to make Foursquare API call\n",
    "url = 'https://api.foursquare.com/v2/venues/categories/?&client_id={}&client_secret={}&v={}'.format(\n",
    "        CLIENT_ID, \n",
    "        CLIENT_SECRET,\n",
    "        VERSION)\n",
    "\n",
    "# read response received from Foursquare request\n",
    "url_response = {}\n",
    "while url_response == {}:\n",
    "    try:\n",
    "        url_response = requests.get(url).json()\n",
    "        break\n",
    "    except:\n",
    "        print(\"Connection refused by the server..\")\n",
    "        time.sleep(10)\n",
    "        url_response = {}\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find out the main categories of Foursquare venues and their ids to create request URL\n",
    "# dict_venues_top_categories = {}\n",
    "# for i in range(len(url_response[\"response\"]['categories'])) :\n",
    "#     dict_venues_top_categories[url_response[\"response\"]['categories'][i][\"name\"]] = url_response[\"response\"]['categories'][i][\"id\"]\n",
    "    \n",
    "# dict_venues_top_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me give some information about these main venue categories:\\\n",
    "1) Arts & Entertainment: Movies theaters, museum, sports stadium, theme park, zoo, etc.\\\n",
    "2) College & University: University, college, school, grounds, etc.\\\n",
    "3) Event: Street sale, festival place, main market, etc.\\\n",
    "4) Food: Restaurant, bakery, coffee shop, cafe, etc.\\\n",
    "5) Nightlife Spot: Bar, lounge, pub, etc.\\\n",
    "6) Outdoors & Recreation: Botanical garden, gym, pool, track, hill, farm, forest, lake, river, etc.\\\n",
    "7) Professional & Other Places: Business center, distribution center, factory, government building, hospitals, camps, etc.\\\n",
    "8) Residence: Home, bungalow, apartments, residential building, etc.\\\n",
    "9) Shop & Service: ATM, bank, shops, petrol pumps, salons, etc.\\\n",
    "10) Travel & Transport: bus/railway/metro station, airport, hotels, tunnels, roads, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will create Foursquare url request and handle/return the received response\n",
    "def venues_extractor (client_id, client_secret, version, radius, lat, long) :\n",
    "    \n",
    "    dict_venues_category = {}\n",
    "    url_response = {}\n",
    "   \n",
    "    for venue_category_id in list(dict_venues_top_categories.values()):\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&v={}&ll={},{}&radius={}&categoryId={}'.format(\n",
    "                client_id, \n",
    "                client_secret, \n",
    "                version, \n",
    "                lat, \n",
    "                long, \n",
    "                radius, \n",
    "                venue_category_id)               \n",
    "                \n",
    "        url_response = {}\n",
    "        error_count = 0\n",
    "        while url_response == {}:\n",
    "            try:\n",
    "                url_response = requests.get(url).json()\n",
    "                if 'totalResults' in  url_response['response'].keys():\n",
    "                    error_count = 0\n",
    "                    break\n",
    "                elif error_count > 5 :\n",
    "                    time.sleep(10)\n",
    "                    url_response = {}\n",
    "                    error_count = 0\n",
    "                    continue\n",
    "                else :\n",
    "                    print(\"Invalid data sent by the server..\")\n",
    "                    time.sleep(10)\n",
    "                    url_response = {}\n",
    "                    error_count = error_count + 1\n",
    "                    continue\n",
    "            except:\n",
    "                print(\"Connection refused by the server..\")\n",
    "                time.sleep(10)\n",
    "                url_response = {}\n",
    "                continue\n",
    "        \n",
    "        if error_count >= 5 :\n",
    "            dict_venues_category[list(dict_venues_top_categories.keys())[list(dict_venues_top_categories.values()).index(venue_category_id)]] = 0\n",
    "        else :\n",
    "            dict_venues_category[list(dict_venues_top_categories.keys())[list(dict_venues_top_categories.values()).index(venue_category_id)]] = url_response['response']['totalResults'] \n",
    "        time.sleep(0.01)\n",
    "        \n",
    "    return dict_venues_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the above function for different trip destinations and save the response to CSV\n",
    "\n",
    "df_venues_category = pd.DataFrame()\n",
    "\n",
    "# call the defined function and extract the venues\n",
    "for lat, long in zip(df_trip_destinations[\"stop_lat\"], df_trip_destinations[\"stop_lon\"]) :\n",
    "    dict_venues_category = venues_extractor(CLIENT_ID,\n",
    "                                           CLIENT_SECRET,\n",
    "                                           VERSION,\n",
    "                                           RADIUS,                                                                   \n",
    "                                           lat,\n",
    "                                           long\n",
    "                                           )\n",
    "    #######################\n",
    "    # develope a dataframe that contains all the venues for given neighbourhood    \n",
    "    df_venues_category = pd.concat([df_venues_category, pd.DataFrame(dict_venues_category, index = [len(df_venues_category)])])\n",
    " \n",
    "df_venues_category.to_csv(f\"{resource_directory}stops_foursquare_data.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read-out CSV containing destination location information (venue details) and combine with stop-id co-ordinates to form dataframe for clustering\n",
    "df_venues_category = pd.read_csv(f\"{resource_directory}stops_foursquare_data.txt\")\n",
    "df_trip_destinations = df_trip_destinations.join(df_venues_category)\n",
    "df_trip_destinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Clustering the data on the basis of stop location/venue details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's normalize the dataframe to train the model \n",
    "df_trip_destinations_nrmlzd = df_trip_destinations.iloc[:, 5:]\n",
    "df_trip_destinations_nrmlzd = df_trip_destinations_nrmlzd.div(df_trip_destinations_nrmlzd.sum())\n",
    "df_trip_destinations_nrmlzd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find-out best value of k\n",
    "# instantiate the clustering model and visualizer, we'll use a fixed random state to make randomness deterministic.\n",
    "model = KMeans(random_state=0)\n",
    "visualizer = KElbowVisualizer(model, k=(1,20), timings=False)\n",
    "# fit the data to the visualizer and get elbow value\n",
    "best_k = visualizer.fit(df_trip_destinations_nrmlzd.values).elbow_value_  \n",
    "visualizer.show() # finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with best value of k and find-out cluster labels\n",
    "\n",
    "kclusters = best_k\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(df_trip_destinations_nrmlzd.values)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# insert the cluster labels to our dataframe\n",
    "df_trip_destinations_clustered = df_trip_destinations.copy()\n",
    "df_trip_destinations_clustered.insert(5, 'cluster_label', kmeans.labels_)\n",
    "df_trip_destinations_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create map\n",
    "map_trip_destinations_clustered = folium.Map(location=[df_trip_destinations_clustered[\"stop_lat\"].mean(), df_trip_destinations_clustered[\"stop_lon\"].mean()], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "# colors_array = cm.rainbow(np.linspace(0, 1, kclusters))\n",
    "# colors_array = [colors.rgb2hex(i) for i in colors_array]\n",
    "colors_array = ['#000000', '#FF0000', '#0000FF', '#FF00FF']\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(df_trip_destinations_clustered['stop_lat'], df_trip_destinations_clustered['stop_lon'], df_trip_destinations_clustered['stop_name'], df_trip_destinations_clustered['cluster_label']):\n",
    "    label = folium.Popup(str(poi) + '\\n - \\n Cluster' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=colors_array[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=colors_array[cluster-1],\n",
    "        fill_opacity=1).add_to(map_trip_destinations_clustered)\n",
    "    \n",
    "map_trip_destinations_clustered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check how clustering is done..\n",
    "colors_array = ['#FF00FF', '#000000', '#FF0000', '#0000FF']\n",
    "df_trip_destinations_nrmlzd_for_plt = df_trip_destinations_nrmlzd.copy()\n",
    "df_trip_destinations_nrmlzd_for_plt.insert(0, 'cluster_label', kmeans.labels_)\n",
    "df_trip_destinations_nrmlzd_for_plt = df_trip_destinations_nrmlzd_for_plt.groupby(\"cluster_label\").describe()\n",
    "df_trip_destinations_nrmlzd_for_plt = df_trip_destinations_nrmlzd_for_plt.loc[:,df_trip_destinations_nrmlzd_for_plt.columns.get_level_values(1).isin({\"75%\"})]\n",
    "df_trip_destinations_nrmlzd_for_plt = df_trip_destinations_nrmlzd_for_plt.transpose()\n",
    "df_trip_destinations_nrmlzd_for_plt.index = [x[0] for x in df_trip_destinations_nrmlzd_for_plt.index.to_list()]\n",
    "df_trip_destinations_nrmlzd_for_plt.plot(color=colors_array)\n",
    "plt.xticks(range(0,len(df_trip_destinations_nrmlzd_for_plt.index)), df_trip_destinations_nrmlzd_for_plt.index, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bus_stop_count for each cluster\n",
    "df_trip_destinations_clustered[\"cluster_label\"].value_counts().to_frame().rename(columns={\"cluster_label\":\"bus_stop_count\"}).plot(kind='bar')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion :\n",
    "\n",
    "What are cluster 1 & 2?\n",
    "There are two significant differences between these two clusters (Number of Events and\n",
    "travel/transport venues). Cluster 2 contains the highest amount of transport venues\n",
    "compared to any of the clusters. Cluster 1 is very similar to cluster 2 with the only\n",
    "significant difference in the number of Events venues.\n",
    "\n",
    "What are cluster 0 & 3?\n",
    "Cluster 0 has a smaller number of venues compared to any of the other clusters.\n",
    "Cluster 3 has more venues than cluster 0 but lesser than cluster 1 or 2.\n",
    "\n",
    "So, from the above observation and plot, we can say that:\n",
    "- Cluster 2 is a developed part of the city and contains bus stops that are close to\n",
    "transport venues such as railway / bus / metro stations or airports etc.\n",
    "- Cluster 1 is also a developed part of the city with the highest amount of Event\n",
    "venues.\n",
    "- Cluster 0 is remote / underdeveloped part of the city and\n",
    "- Cluster 3 is a developing part of the city.\n",
    "- From the map, we can say that, although clusters 1,2, and 3 have lesser bus stops,\n",
    "they are densely located. This suggests that bus-stops have very good connectivity\n",
    "in the central / old part of the city.\n",
    "\n",
    "From the bar chart, we can say that bus service has a great network in for remote parts of the city (cluster 0), then it also covers travel / transport venues with a comparatively (compared to cluster 1) higher number of bus stops (cluster 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize the bus frequency \n",
    "let's cluster the data based on total trip_count per bus-stop and find-out busiest bus-stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's normalize the dataframe to train the model \n",
    "df_trip_destinations_nrmlzd = df_trip_destinations.filter(items=[\"trip_count\"])\n",
    "df_trip_destinations_nrmlzd = df_trip_destinations_nrmlzd.div(df_trip_destinations_nrmlzd.sum())\n",
    "df_trip_destinations_nrmlzd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find-out best value of k\n",
    "# instantiate the clustering model and visualizer, we'll use fixed random state to make randomness deterministic.\n",
    "model = KMeans(random_state=0)\n",
    "visualizer = KElbowVisualizer(model, k=(1,20), timings=False)\n",
    "# fit the data to the visualizer and get elbow value\n",
    "best_k = visualizer.fit(df_trip_destinations_nrmlzd.values).elbow_value_  \n",
    "visualizer.show() # finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with best value of k and find-out cluster labels\n",
    "\n",
    "kclusters = best_k\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(df_trip_destinations_nrmlzd.values)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# insert the cluster labels to our dataframe\n",
    "df_trip_destinations_clustered = df_trip_destinations.copy()\n",
    "df_trip_destinations_clustered.insert(5, 'cluster_label', kmeans.labels_)\n",
    "df_trip_destinations_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check how clustering is done...\n",
    "df_trip_destinations_nrmlzd_for_plt = df_trip_destinations_clustered[[\"cluster_label\",\"trip_count\"]].copy()\n",
    "df_trip_destinations_nrmlzd_for_plt = df_trip_destinations_nrmlzd_for_plt.groupby(\"cluster_label\").describe()\n",
    "df_trip_destinations_nrmlzd_for_plt = df_trip_destinations_nrmlzd_for_plt.loc[:,df_trip_destinations_nrmlzd_for_plt.columns.get_level_values(1).isin({\"75%\"})]\n",
    "\n",
    "df_trip_destinations_nrmlzd_for_plt.plot(kind=\"bar\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bus stops in cluster 1 & 2 are the busiest\n",
    "# let's keep bus stops from cluster 1 & 2, and drop other for further analysis\n",
    "df_trip_destinations_clustered = df_trip_destinations_clustered[(df_trip_destinations_clustered[\"cluster_label\"]==1) | (df_trip_destinations_clustered[\"cluster_label\"]==2)]\n",
    "df_trip_destinations_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "map_trip_destinations_clustered = folium.Map(location=[df_trip_destinations_clustered[\"stop_lat\"].mean(), df_trip_destinations_clustered[\"stop_lon\"].mean()], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, kclusters))\n",
    "colors_array = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(df_trip_destinations_clustered['stop_lat'], df_trip_destinations_clustered['stop_lon'], df_trip_destinations_clustered['stop_name'], df_trip_destinations_clustered['cluster_label']):\n",
    "    label = folium.Popup(str(poi) + '\\n - \\n Cluster' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=colors_array[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=colors_array[cluster-1],\n",
    "        fill_opacity=1).add_to(map_trip_destinations_clustered)\n",
    "       \n",
    "map_trip_destinations_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we know the busiest bus stop ids, lets capture trips that include filtered stop_id\n",
    "df1 = df_BusScheduleInfo.join(df_trip_destinations_clustered.filter(items=[\"trip_end_stop_id\"]).set_index(\"trip_end_stop_id\"), on=\"trip_end_stop_id\", how =\"inner\").reset_index(drop=True)\n",
    "df2 = df_BusScheduleInfo.join(df_trip_destinations_clustered.filter(items=[\"trip_end_stop_id\"]).set_index(\"trip_end_stop_id\"), on=\"trip_bgn_stop_id\", how =\"inner\").reset_index(drop=True)\n",
    "df_BusScheduleInfo = df1.append(df2).reset_index(drop=True)\n",
    "df_BusScheduleInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize the data.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes for filtering the bus scheduling bus information from dataframe\n",
    "start_datetime = datetime.datetime(2019,8,2,0,0,0) # let's look at the bus frequency on friday 02/08/2019\n",
    "stop_datetime = datetime.datetime(2019,8,3,2,0,0)\n",
    "delta_time = datetime.timedelta(minutes=2) # check the bus frequency for every 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out which service_ids are running on the above day\n",
    "service_datetime = start_datetime\n",
    "service_day = (service_datetime.strftime('%A')).lower()\n",
    "service_date = int(str(service_datetime.date()).replace(\"-\",\"\"))\n",
    "df_ServiceID = df_TripCalendar[(df_TripCalendar[\"start_date\"] <= service_date) & (df_TripCalendar[\"end_date\"] >= service_date)]\n",
    "df_ServiceID = df_ServiceID[[\"service_id\",service_day]]\n",
    "df_ServiceID = df_ServiceID[df_ServiceID[service_day] == 1][[\"service_id\"]]\n",
    "df_ServiceID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filter-out the bus schedule information based on running service_ids and adjust the datetime according to our requirement\n",
    "df_BusLocationWithDT = pd.DataFrame()\n",
    "df_BusLocationWithDT = df_ServiceID.join(df_BusScheduleInfo.set_index(\"service_id\"), on = \"service_id\")  \n",
    "df_BusLocationWithDT[[\"trip_bgn_time\", \"trip_end_time\", \"arrival_time\", \"departure_time\"]] = df_BusLocationWithDT[[\"trip_bgn_time\", \"trip_end_time\", \"arrival_time\", \"departure_time\"]] + (start_datetime.date() - df_BusLocationWithDT[\"trip_bgn_time\"].min().date())\n",
    "df_BusLocationWithDT.reset_index(drop = True, inplace=True)\n",
    "df_BusLocationWithDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a dataframe that will contain no. of buses in motion for every 2 minutes\n",
    "df_UniqueBusTripsWithDT = df_BusLocationWithDT.groupby(\"trip_id\").head(1).reset_index(drop=True)\n",
    "df_LiveBusCount = pd.DataFrame()\n",
    "service_datetime = start_datetime\n",
    "while service_datetime <= stop_datetime:\n",
    "    live_count = df_UniqueBusTripsWithDT[((service_datetime >= df_UniqueBusTripsWithDT[\"trip_bgn_time\"]) & (service_datetime <= df_UniqueBusTripsWithDT[\"trip_end_time\"]))][\"trip_id\"].count()\n",
    "    dict_live_count = {\"date_time\" : service_datetime, \"live_count\" : live_count}\n",
    "    df_temp = pd.DataFrame(dict_live_count, index = [len(df_LiveBusCount)])\n",
    "    df_LiveBusCount = pd.concat([df_LiveBusCount, df_temp]) \n",
    "    service_datetime = service_datetime + delta_time\n",
    "df_LiveBusCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the no. of buses in motion vs datetime\n",
    "df_LiveBusCount.set_index('date_time', inplace=True)\n",
    "df_LiveBusCount.index = pd.to_datetime(df_LiveBusCount.index)\n",
    "df_LiveBusCount.plot(figsize=(20,10), grid = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "From the plot, we can say that bus frequency rapidly increases around 6 am and touches the morning peak of approx. 660 buses in motion at around 9:30 am. We can call it 'morning rush'.\\\n",
    "After the noon bus frequency again increases close to 700 buses in motion and remains there up till 05:00 pm.\\\n",
    "Between 05:00 pm to 07:30 pm bus frequency is close to 750 buses in motion, we can call it as 'evening rush'.\\\n",
    "From 07:30 pm onwards frequency declines gradually till 10:00 pm, and after that, it takes a plunge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize the bus transit frequency on the map, we should save the images of bus location for respective datetime\n",
    "# on the map and convert those bunch of images into .gif below code will create the images of all the bus locations for \n",
    "# respective time and save them in .png format, later we'll convert them into .gif\n",
    "\n",
    "service_datetime = start_datetime\n",
    "while service_datetime <= stop_datetime:    \n",
    "    df_filtered_BusLocationWithDT = df_BusLocationWithDT[((service_datetime >= df_BusLocationWithDT[\"trip_bgn_time\"]) & (service_datetime <= df_BusLocationWithDT[\"trip_end_time\"]) & (service_datetime >= df_BusLocationWithDT[\"arrival_time\"]))]\n",
    "    df_filtered_BusLocationWithDT = df_filtered_BusLocationWithDT[df_filtered_BusLocationWithDT.groupby(\"trip_id\")[\"stop_sequence\"].transform(max) == df_filtered_BusLocationWithDT[\"stop_sequence\"]]\n",
    "   \n",
    "    map_pune = folium.Map(location=[df_BusStops[\"stop_lat\"].mean(), df_BusStops[\"stop_lon\"].mean()], \n",
    "                      tiles='CartoDB dark_matter',\n",
    "                      zoom_start=12)    \n",
    "    \n",
    "    for lat, lng, label, stop_id in zip(df_trip_destinations_clustered[\"stop_lat\"], df_filtered_BusLocationWithDT[\"stop_lon\"], df_trip_destinations_clustered[\"stop_name\"], df_trip_destinations_clustered[\"trip_end_stop_id\"]) :\n",
    "        folium.CircleMarker(\n",
    "                            location = [lat, lng],\n",
    "                            radius=4,\n",
    "                            fill_opacity=1.0,\n",
    "                            fill_color = '#FF3030',\n",
    "                            color = '#FF3030',\n",
    "                            popup=label\n",
    "                            ).add_to(map_pune)\n",
    "\n",
    "    for lat, lng, color, label in zip(df_filtered_BusLocationWithDT[\"stop_lat\"], df_filtered_BusLocationWithDT[\"stop_lon\"], df_filtered_BusLocationWithDT[\"trip_color\"], df_filtered_BusLocationWithDT[\"trip_headsign\"]) :\n",
    "        folium.RegularPolygonMarker(\n",
    "                                    location = [lat, lng],\n",
    "                                    number_of_sides=4,\n",
    "                                    radius=4,\n",
    "                                    color = '#00FFFF',\n",
    "                                    #color = color,\n",
    "                                    fill_opacity=1.0,\n",
    "                                    fill_color = '#00FFFF',\n",
    "                                    popup=label\n",
    "                                    ).add_to(map_pune)\n",
    "    \n",
    "    folium.Marker([18.486872, 73.613156], \n",
    "                  icon=DivIcon(\n",
    "                                icon_size=(150,36),\n",
    "                                icon_anchor=(7,20),\n",
    "                                html=f'<div style=\"font-size: 40pt; color : white\">{service_datetime}</div>')\n",
    "                ).add_to(map_pune)   \n",
    "    \n",
    "    img_data = map_pune._to_png()\n",
    "    img = Image.open(io.BytesIO(img_data))\n",
    "    img.save(f\"00_Ntbk_Resources\\\\01_DataAnalysis\\\\01_ImagesForGIF\\\\image1.png\")\n",
    "\n",
    "    service_datetime = service_datetime + delta_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we've images/frames that can be used to make GIF.\\\n",
    "There are approx. 819 images/frames (size: 339 MB), since combining these images to form GIF will require lot of memory, We've used 'PhotoScape X' software (Windows 10) to make GIF.\\\n",
    "Settings for software are :\\\n",
    "Frame rate : 20 frames/sec\\\n",
    "Frame size : 500 x 251 px\\\n",
    "Loop : Infinite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion :\\\n",
    "From the .gif visualization we can conclude on the following points:\n",
    "\n",
    "1) There are approx. 7 roads that are used by bus trips to connect/pass through the central part of the city.\\\n",
    "2) Bus frequency is fairly similar on every bus stop on these 7 main roads of the city for any given period.\\\n",
    "3) We can observe comparatively high traffic in the central part of the city from 7:30 am to 10:30 pm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
